{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import face_recognition\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['chiranjeevi','modi','nagarjuna','rajinikanth']\n",
    "links=[]\n",
    "target=[]\n",
    "df=pd.DataFrame()\n",
    "for col in cols:\n",
    "    for i in os.listdir(col):\n",
    "        links.append(os.path.join(col,i))\n",
    "    target+=[col]*len(os.listdir(col))\n",
    "df['links']=links\n",
    "df['target']=target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_of_image(link):\n",
    "    test=face_recognition.load_image_file(link)\n",
    "    face_location=face_recognition.face_locations(test)\n",
    "    if len(face_location)==0:\n",
    "        return None\n",
    "    for top,right,bottom,left in face_location:\n",
    "        test=test[top:bottom,left:right]\n",
    "        return test/255.0\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_face(image):\n",
    "    face_model = cv2.CascadeClassifier('haar_face.xml')\n",
    "    coordinates = face_model.detectMultiScale(image)\n",
    "    if len(coordinates) == 0:\n",
    "        return None  # If no face detected, return None\n",
    "    for (x, y, w, h) in coordinates:\n",
    "        face = image[y:y+h, x:x+w]\n",
    "        return face/255.0\n",
    "    return None  # Return None if no face is detected\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_image(link):\n",
    "    image = cv2.imread(link)\n",
    "    if image is None:\n",
    "        print(f\"Error loading image: {link}\")\n",
    "        return None\n",
    "    image_face = face_of_image(link)\n",
    "    if image_face is not None:\n",
    "        try:\n",
    "            image_face = cv2.resize(image_face, (100, 100))\n",
    "            return image_face\n",
    "        except cv2.error as e:\n",
    "            print(f\"Error resizing image: {link}, {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        try:\n",
    "            image = cv2.resize(image, (100, 100))\n",
    "            return image\n",
    "        except cv2.error as e:\n",
    "            print(f\"Error resizing image: {link}, {e}\")\n",
    "            return None\n",
    "\n",
    "df['image'] = df['links'].apply(lambda x: get_image(x))\n",
    "df = df[df['image'].notnull()]  # Remove rows where image processing failed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.loc[np.random.permutation(df.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D,Flatten,Dense,MaxPooling2D\n",
    "from tensorflow.keras import Sequential\n",
    "model=Sequential([\n",
    "    Conv2D(filters=32,kernel_size=3,padding='same',activation='relu'),\n",
    "    Conv2D(filters=32,kernel_size=3,padding='same',activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Conv2D(filters=64,kernel_size=3,padding='same',activation='relu'),\n",
    "    Conv2D(filters=64,kernel_size=3,padding='same',activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2,2)),\n",
    "    Flatten(),\n",
    "    Dense(200,activation='relu'),\n",
    "    Dense(4,activation='softmax')\n",
    "])\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.target=df.target.map({'chiranjeevi':0,'modi':1,'nagarjuna':2,'rajinikanth':3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n",
      "int64\n"
     ]
    }
   ],
   "source": [
    "X = np.array(df.image.tolist())\n",
    "y = df.target\n",
    "X=X.astype('float32')\n",
    "print(X.dtype)\n",
    "print(y.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=pd.get_dummies(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1s/step - accuracy: 0.2843 - loss: 34.9354\n",
      "Epoch 2/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.3503 - loss: 5.4175\n",
      "Epoch 3/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 980ms/step - accuracy: 0.3369 - loss: 2.7241\n",
      "Epoch 4/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 935ms/step - accuracy: 0.2795 - loss: 1.6549\n",
      "Epoch 5/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 929ms/step - accuracy: 0.3539 - loss: 1.4000\n",
      "Epoch 6/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 922ms/step - accuracy: 0.3131 - loss: 1.3731\n",
      "Epoch 7/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 934ms/step - accuracy: 0.3780 - loss: 1.3110\n",
      "Epoch 8/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 957ms/step - accuracy: 0.3644 - loss: 1.3101\n",
      "Epoch 9/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 925ms/step - accuracy: 0.5341 - loss: 1.2356\n",
      "Epoch 10/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 930ms/step - accuracy: 0.5329 - loss: 1.1858\n",
      "Epoch 11/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 921ms/step - accuracy: 0.5962 - loss: 1.1191\n",
      "Epoch 12/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 928ms/step - accuracy: 0.6405 - loss: 0.9785\n",
      "Epoch 13/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 923ms/step - accuracy: 0.7190 - loss: 0.8191\n",
      "Epoch 14/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 934ms/step - accuracy: 0.7814 - loss: 0.7068\n",
      "Epoch 15/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 925ms/step - accuracy: 0.7697 - loss: 0.6396\n",
      "Epoch 16/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 929ms/step - accuracy: 0.8509 - loss: 0.5061\n",
      "Epoch 17/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 925ms/step - accuracy: 0.8510 - loss: 0.4265\n",
      "Epoch 18/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 933ms/step - accuracy: 0.8911 - loss: 0.2992\n",
      "Epoch 19/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 937ms/step - accuracy: 0.9605 - loss: 0.2165\n",
      "Epoch 20/20\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 928ms/step - accuracy: 0.9706 - loss: 0.1612\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X,y,epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapp={0:'chiranjeevi',1:'modi',2:'nagarjuna',3:'rajinikanth'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 339ms/step\n"
     ]
    }
   ],
   "source": [
    "y_test=model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n"
     ]
    }
   ],
   "source": [
    "def get_name(link):\n",
    "    image=get_image(link)\n",
    "    test_image=image.reshape(-1,100,100,3)\n",
    "    y_pred=model.predict(test_image)\n",
    "    name=mapp[y_pred.argmax()]\n",
    "    return [image,name]\n",
    "image,name=get_name(\"rajinikanth_test_image.jpeg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.putText(image,name,(10,95),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,255))\n",
    "cv2.imshow('image',image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.apply(lambda x: x.idxmax(),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ped=[x.argmax() for x in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['face_recognizer.joblib']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(model,'face_recognizer.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
